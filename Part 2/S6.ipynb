{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yRE9v0hEH2Cz","executionInfo":{"status":"ok","timestamp":1709355730585,"user_tz":-240,"elapsed":2720,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"a09ddf0c-03ce-4690-bc1f-466b1935cb0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 's6-backprop'...\n","remote: Enumerating objects: 437, done.\u001b[K\n","remote: Counting objects: 100% (215/215), done.\u001b[K\n","remote: Compressing objects: 100% (142/142), done.\u001b[K\n","remote: Total 437 (delta 126), reused 158 (delta 69), pack-reused 222\u001b[K\n","Receiving objects: 100% (437/437), 23.52 MiB | 19.62 MiB/s, done.\n","Resolving deltas: 100% (262/262), done.\n"]}],"source":["!git clone 'https://github.com/aakashvardhan/s6-backprop.git'"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/s6-backprop/Part 2')"],"metadata":{"id":"vu-V9vQsIFza","executionInfo":{"status":"ok","timestamp":1709355730585,"user_tz":-240,"elapsed":2,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Importing torchvision for handling datasets and applying transformations\n","from torchvision import datasets, transforms\n","\n","# Importing PyTorch Library\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","# Importing python files, including CNN model, train & test the model\n","from model import Net, model_summary, test_model_sanity\n","from utils import train, test, plt_fig\n","\n","# Import the Matplotlib library for plotting\n","import matplotlib.pyplot as plt\n","\n","!pip install torchsummary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"LrPib8-OIWhu","executionInfo":{"status":"error","timestamp":1709355740442,"user_tz":-240,"elapsed":9858,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"727c224d-2f82-4f26-ec00-c3d4e9f49c26"},"execution_count":3,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (model.py, line 126)","traceback":["Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n","  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n","\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-0f49eeaa8fb6>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0;36m, in \u001b[0;35m<cell line: 10>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from model import Net, model_summary, test_model_sanity\u001b[0m\n","\u001b[0;36m  File \u001b[0;32m\"/content/s6-backprop/Part 2/model.py\"\u001b[0;36m, line \u001b[0;32m126\u001b[0m\n\u001b[0;31m    final_loss = loss_function(model(data), target,def test_model_sanity():\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["# Check if CUDA is available on the system and set `use_cuda` accordingly\n","use_cuda = torch.cuda.is_available()\n","\n","# Set the device to \"cuda\" if CUDA is available, otherwise fall back to using the CPU\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","# Initialize the model and move it to the specified device (either GPU or CPU)\n","model = Net().to(device)"],"metadata":{"id":"5mE7I_1TIefo","executionInfo":{"status":"aborted","timestamp":1709355740443,"user_tz":-240,"elapsed":2,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_summary(model)"],"metadata":{"id":"DNcDKMxaImZj","executionInfo":{"status":"aborted","timestamp":1709355740443,"user_tz":-240,"elapsed":2,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_model_sanity()"],"metadata":{"id":"SjJx8w5IddRV","executionInfo":{"status":"aborted","timestamp":1709355740443,"user_tz":-240,"elapsed":2,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This block of code is used to define transformations for the training dataset.\n","train_transforms = transforms.Compose([\n","    # Randomly applies a center crop of size 22 to the input image with a probability of 0.1.\n","    transforms.RandomApply([transforms.CenterCrop(22), ], p=0.1),\n","    # Resizes the input image to a size of 28x28 pixels.\n","    transforms.Resize((28, 28)),\n","    # Randomly rotates the input image within a range of -15 to 15 degrees. The areas left after rotation are filled with 0 (black).\n","    transforms.RandomRotation((-15., 15.), fill=0),\n","    # Converts the input image to a PyTorch tensor.\n","    transforms.ToTensor(),\n","    # Normalizes the input tensor with a mean of 0.1307 and a standard deviation of 0.3081.\n","    transforms.Normalize((0.1307,), (0.3081,)),\n","])\n","\n","# This block of code is used to define transformations for the testing dataset.\n","test_transforms = transforms.Compose([\n","    # Converts the input image to a PyTorch tensor.\n","    transforms.ToTensor(),\n","    # Normalizes the input tensor with a mean of 0.1307 and a standard deviation of 0.3081.\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])"],"metadata":{"id":"0CVLR-PRI9Qt","executionInfo":{"status":"aborted","timestamp":1709355308210,"user_tz":-240,"elapsed":4,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MNIST Training dataset with specified transformation\n","train_data = datasets.MNIST('../data', train=True, download=True, transform=train_transforms)\n","# MNIST Testing dataset with specified transformation\n","test_data = datasets.MNIST('../data', train=False, download=True, transform=test_transforms)"],"metadata":{"id":"8fP9W6DpAqdm","executionInfo":{"status":"aborted","timestamp":1709355308210,"user_tz":-240,"elapsed":4,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the batch size to 512, indicating the number of samples to be processed in one go.\n","batch_size = 512\n","\n","# Define a dictionary of keyword arguments for the DataLoader:\n","# 'batch_size': Specifies the number of samples in each batch.\n","# 'shuffle': If True, the dataset will be shuffled at the beginning of each epoch to reduce model overfitting.\n","# 'num_workers': Sets the number of subprocesses to use for data loading. Utilizing multiple workers can enhance data loading throughput.\n","# 'pin_memory': When set to True and using a CUDA-enabled GPU, this option pins memory, potentially speeding up data transfer to the GPU.\n","kwargs = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n","\n","# Initialize the DataLoader for the test dataset.\n","# 'test_data': The dataset to use for testing.\n","# The DataLoader handles efficient loading of data from 'test_data' using the parameters defined in 'kwargs'.\n","test_loader = torch.utils.data.DataLoader(test_data, **kwargs)\n","\n","# Initialize the DataLoader for the training dataset.\n","# 'train_data': The dataset to use for training. The DataLoader will shuffle this data if 'shuffle' is True, as per 'kwargs'.\n","# This DataLoader facilitates efficient loading of training data, respecting the parameters specified in 'kwargs'.\n","train_loader = torch.utils.data.DataLoader(train_data, **kwargs)"],"metadata":{"id":"X3b3UJgXAuV3","executionInfo":{"status":"aborted","timestamp":1709355308210,"user_tz":-240,"elapsed":4,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retrieve the first batch of data and labels from the training DataLoader\n","batch_data, batch_label = next(iter(train_loader))\n","\n","# Initialize a new figure for plotting\n","fig = plt.figure()\n","\n","# Loop over the first 12 images and labels in the batch.\n","for i in range(12):\n","  # Create a 3x4 grid of subplots. The index of the current subplot (i+1) is set to active\n","  plt.subplot(3,4,i+1)\n","  # Adjust the layout to prevent overlapping of subplot elements.\n","  plt.tight_layout()\n","  # Display an image. 'squeeze(0)' removes a dimension of size 1, which is common for grayscale images in PyTorch.\n","  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n","  # Set the title of the subplot to the label of the current image. '.item()' converts a PyTorch scalar to a Python number.\n","  plt.title(batch_label[i].item())\n","  # Remove the x-axis ticks.\n","  plt.xticks([])\n","  # Remove the y-axis ticks.\n","  plt.yticks([])"],"metadata":{"id":"kZmHwqVTAxro","executionInfo":{"status":"aborted","timestamp":1709355308210,"user_tz":-240,"elapsed":4,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the model and move it to the specified device (GPU or CPU)\n","model = Net().to(device)\n","\n","# Set up the optimizer for training. Here, we're using Stochastic Gradient Descent (SGD)\n","# with a learning rate of 0.01 and momentum of 0.9 for better convergence\n","optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n","\n","# Define a learning rate scheduler that decreases the learning rate by a factor of 0.1\n","# every 10 epochs to fine-tune the training in later stages\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1, verbose=True)\n","\n","criterion = F.nll_loss\n","\n","# Specify the number of epochs to train the model\n","num_epochs = 19\n","\n","# Start the training loop over the specified number of epochs\n","for epoch in range(1, num_epochs+1):\n","  # Print the current epoch number\n","  print(f'Epoch {epoch}')\n","\n","  # Call the training function for a single epoch with the training data\n","  # Pass the model, device, training data loader, optimizer, and loss function as arguments\n","  train(model, device, train_loader, optimizer, criterion)\n","\n","  # Evaluate the model with the testing data after training\n","  # Pass the model, device, testing data loader, and loss function as arguments\n","  test(model, device, test_loader, criterion)\n","\n","  # Update the learning rate based on the scheduler\n","  scheduler.step()"],"metadata":{"id":"pU2AsIm9Azuz","executionInfo":{"status":"aborted","timestamp":1709355308211,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt_fig()"],"metadata":{"id":"2imf0fp2BFK_","executionInfo":{"status":"aborted","timestamp":1709355308211,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cF0Vz47OTGWK","executionInfo":{"status":"aborted","timestamp":1709355308211,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}