{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yRE9v0hEH2Cz","executionInfo":{"status":"ok","timestamp":1709214047154,"user_tz":-240,"elapsed":22,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"c5214a85-cc4d-4010-a9d0-493f5eb7882d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 's6-backprop'...\n","remote: Enumerating objects: 256, done.\u001b[K\n","remote: Counting objects: 100% (34/34), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 256 (delta 20), reused 23 (delta 10), pack-reused 222\u001b[K\n","Receiving objects: 100% (256/256), 660.23 KiB | 6.23 MiB/s, done.\n","Resolving deltas: 100% (156/156), done.\n"]}],"source":["!git clone 'https://github.com/aakashvardhan/s6-backprop.git'"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/s6-backprop/Part 2')"],"metadata":{"id":"vu-V9vQsIFza","executionInfo":{"status":"ok","timestamp":1709214047154,"user_tz":-240,"elapsed":3,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Importing torchvision for handling datasets and applying transformations\n","from torchvision import datasets, transforms\n","\n","# Importing PyTorch Library\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","# Importing python files, including CNN model, train & test the model\n","from model import Net, model_summary\n","from utils import train, test, plt_fig\n","\n","# Import the Matplotlib library for plotting\n","import matplotlib.pyplot as plt\n","\n","!pip install torchsummary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrPib8-OIWhu","executionInfo":{"status":"ok","timestamp":1709214058054,"user_tz":-240,"elapsed":10903,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"8917dac7-5e79-4df4-9df0-1049d4c3ee73"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"]}]},{"cell_type":"code","source":["# Check if CUDA is available on the system and set `use_cuda` accordingly\n","use_cuda = torch.cuda.is_available()\n","\n","# Set the device to \"cuda\" if CUDA is available, otherwise fall back to using the CPU\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","# Initialize the model and move it to the specified device (either GPU or CPU)\n","model = Net().to(device)"],"metadata":{"id":"5mE7I_1TIefo","executionInfo":{"status":"ok","timestamp":1709214059447,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model_summary(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"id":"DNcDKMxaImZj","executionInfo":{"status":"error","timestamp":1709214062165,"user_tz":-240,"elapsed":2722,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"115d4c38-66a9-4140-e133-4482bcd95aeb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 107008826.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 105887844.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 34277472.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 3853262.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/10 [00:01<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Given input size: (10x14x14). Calculated output size: (10x0x0). Output size is too small","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-149233a6ce55>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/s6-backprop/Part 2/model.py\u001b[0m in \u001b[0;36mmodel_summary\u001b[0;34m(model, input_size)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mtest_model_sanity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/s6-backprop/Part 2/model.py\u001b[0m in \u001b[0;36mtest_model_sanity\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Print the current epoch number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Perform sanity check: the loss should be decreasing after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/s6-backprop/Part 2/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Forward pass - compute the model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/s6-backprop/Part 2/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         return F.avg_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    636\u001b[0m                             self.padding, self.ceil_mode, self.count_include_pad, self.divisor_override)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given input size: (10x14x14). Calculated output size: (10x0x0). Output size is too small"]}]},{"cell_type":"code","source":["# This block of code is used to define transformations for the training dataset.\n","train_transforms = transforms.Compose([\n","    # Randomly applies a center crop of size 22 to the input image with a probability of 0.1.\n","    transforms.RandomApply([transforms.CenterCrop(22), ], p=0.1),\n","    # Resizes the input image to a size of 28x28 pixels.\n","    transforms.Resize((28, 28)),\n","    # Randomly rotates the input image within a range of -15 to 15 degrees. The areas left after rotation are filled with 0 (black).\n","    transforms.RandomRotation((-15., 15.), fill=0),\n","    # Converts the input image to a PyTorch tensor.\n","    transforms.ToTensor(),\n","    # Normalizes the input tensor with a mean of 0.1307 and a standard deviation of 0.3081.\n","    transforms.Normalize((0.1307,), (0.3081,)),\n","])\n","\n","# This block of code is used to define transformations for the testing dataset.\n","test_transforms = transforms.Compose([\n","    # Converts the input image to a PyTorch tensor.\n","    transforms.ToTensor(),\n","    # Normalizes the input tensor with a mean of 0.1407 and a standard deviation of 0.4081.\n","    transforms.Normalize((0.1407,), (0.4081,))\n","])"],"metadata":{"id":"0CVLR-PRI9Qt","executionInfo":{"status":"aborted","timestamp":1709214062165,"user_tz":-240,"elapsed":6,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MNIST Training dataset with specified transformation\n","train_data = datasets.MNIST('../data', train=True, download=True, transform=train_transforms)\n","# MNIST Testing dataset with specified transformation\n","test_data = datasets.MNIST('../data', train=False, download=True, transform=test_transforms)"],"metadata":{"id":"8fP9W6DpAqdm","executionInfo":{"status":"aborted","timestamp":1709214062165,"user_tz":-240,"elapsed":6,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the batch size to 512, indicating the number of samples to be processed in one go.\n","batch_size = 512\n","\n","# Define a dictionary of keyword arguments for the DataLoader:\n","# 'batch_size': Specifies the number of samples in each batch.\n","# 'shuffle': If True, the dataset will be shuffled at the beginning of each epoch to reduce model overfitting.\n","# 'num_workers': Sets the number of subprocesses to use for data loading. Utilizing multiple workers can enhance data loading throughput.\n","# 'pin_memory': When set to True and using a CUDA-enabled GPU, this option pins memory, potentially speeding up data transfer to the GPU.\n","kwargs = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 2, 'pin_memory': True}\n","\n","# Initialize the DataLoader for the test dataset.\n","# 'test_data': The dataset to use for testing.\n","# The DataLoader handles efficient loading of data from 'test_data' using the parameters defined in 'kwargs'.\n","test_loader = torch.utils.data.DataLoader(test_data, **kwargs)\n","\n","# Initialize the DataLoader for the training dataset.\n","# 'train_data': The dataset to use for training. The DataLoader will shuffle this data if 'shuffle' is True, as per 'kwargs'.\n","# This DataLoader facilitates efficient loading of training data, respecting the parameters specified in 'kwargs'.\n","train_loader = torch.utils.data.DataLoader(train_data, **kwargs)"],"metadata":{"id":"X3b3UJgXAuV3","executionInfo":{"status":"aborted","timestamp":1709214062165,"user_tz":-240,"elapsed":6,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retrieve the first batch of data and labels from the training DataLoader\n","batch_data, batch_label = next(iter(train_loader))\n","\n","# Initialize a new figure for plotting\n","fig = plt.figure()\n","\n","# Loop over the first 12 images and labels in the batch.\n","for i in range(12):\n","  # Create a 3x4 grid of subplots. The index of the current subplot (i+1) is set to active\n","  plt.subplot(3,4,i+1)\n","  # Adjust the layout to prevent overlapping of subplot elements.\n","  plt.tight_layout()\n","  # Display an image. 'squeeze(0)' removes a dimension of size 1, which is common for grayscale images in PyTorch.\n","  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n","  # Set the title of the subplot to the label of the current image. '.item()' converts a PyTorch scalar to a Python number.\n","  plt.title(batch_label[i].item())\n","  # Remove the x-axis ticks.\n","  plt.xticks([])\n","  # Remove the y-axis ticks.\n","  plt.yticks([])"],"metadata":{"id":"kZmHwqVTAxro","executionInfo":{"status":"aborted","timestamp":1709214062166,"user_tz":-240,"elapsed":7,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the model and move it to the specified device (GPU or CPU)\n","model = Net().to(device)\n","\n","# Set up the optimizer for training. Here, we're using Stochastic Gradient Descent (SGD)\n","# with a learning rate of 0.01 and momentum of 0.9 for better convergence\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","# Define a learning rate scheduler that decreases the learning rate by a factor of 0.1\n","# every 15 epochs to fine-tune the training in later stages\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1, verbose=True)\n","\n","# Define the loss function. Here, Negative Log Likelihood Loss is used, suitable for classification problems\n","criterion = F.nll_loss\n","\n","# Specify the number of epochs to train the model\n","num_epochs = 18\n","\n","# Start the training loop over the specified number of epochs\n","for epoch in range(1, num_epochs+1):\n","  # Print the current epoch number\n","  print(f'Epoch {epoch}')\n","\n","  # Call the training function for a single epoch with the training data\n","  # Pass the model, device, training data loader, optimizer, and loss function as arguments\n","  train(model, device, train_loader, optimizer,epoch)\n","\n","  # Evaluate the model with the testing data after training\n","  # Pass the model, device, testing data loader, and loss function as arguments\n","  test(model, device, test_loader)\n","\n","  # Update the learning rate based on the scheduler\n","  scheduler.step()"],"metadata":{"id":"pU2AsIm9Azuz","executionInfo":{"status":"aborted","timestamp":1709214062166,"user_tz":-240,"elapsed":6,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2imf0fp2BFK_","executionInfo":{"status":"aborted","timestamp":1709214062166,"user_tz":-240,"elapsed":6,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}